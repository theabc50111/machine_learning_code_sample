{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape:  (113, 20)\n",
      "test_features:  (33, 20)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/output/Enron_train_data_clean.csv')\n",
    "test_features = pd.read_csv('./data/output/Enron_test_features_clean.csv')\n",
    "train_data_y = train_data['poi']\n",
    "train_data = train_data.drop(['poi'],axis=1)\n",
    "print('train_data shape: ', train_data.shape)\n",
    "print('test_features: ', test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid score of logistic:0.9130434782608695\n",
      "valid score of SVM:0.782608695652174\n",
      "valid score of naive bayes:0.8260869565217391\n",
      "valid score of DecisionTree:0.9565217391304348\n",
      "valid score of RandomForest:0.9130434782608695\n",
      "valid score of AdaBoost:0.9565217391304348\n",
      "valid score of Perceptron:1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(train_data,train_data_y,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "lg = LogisticRegression()\n",
    "svm = SVC(probability= True)\n",
    "nb = GaussianNB()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "per =  Perceptron()\n",
    "\n",
    "\n",
    "lg.fit(x_train,y_train)\n",
    "y_pred_lg = lg.predict(x_valid)\n",
    "print(f'valid score of logistic:{accuracy_score(y_valid,y_pred_lg)}')\n",
    "svm.fit(x_train,y_train)\n",
    "y_pred_svm = svm.predict(x_valid)\n",
    "print(f'valid score of SVM:{accuracy_score(y_valid,y_pred_svm)}')\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred_nb = nb.predict(x_valid)\n",
    "print(f'valid score of naive bayes:{accuracy_score(y_valid,y_pred_nb)}')\n",
    "dt.fit(x_train,y_train)\n",
    "y_pred_dt = dt.predict(x_valid)\n",
    "print(f'valid score of DecisionTree:{accuracy_score(y_valid,y_pred_dt)}')\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred_rf = rf.predict(x_valid)\n",
    "print(f'valid score of RandomForest:{accuracy_score(y_valid,y_pred_rf)}')\n",
    "ada.fit(x_train,y_train)\n",
    "y_pred_ada = ada.predict(x_valid)\n",
    "print(f'valid score of AdaBoost:{accuracy_score(y_valid,y_pred_ada)}')\n",
    "per.fit(x_train,y_train)\n",
    "y_pred_per = per.predict(x_valid)\n",
    "print(f'valid score of Perceptron:{accuracy_score(y_valid,y_pred_per)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall & Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 3]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix([0, 1, 0, 1, 1, 1], [1, 1, 1, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix in sklearn \n",
    "| TN | FP |\n",
    "|----|----|\n",
    "| FN | TP |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix of logistic:\n",
      "[[18  0]\n",
      " [ 2  3]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "confusion matrix of SVM:\n",
      "[[18  0]\n",
      " [ 5  0]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "confusion matrix of naive bayes:\n",
      "[[18  0]\n",
      " [ 4  1]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "confusion matrix of DecisionTree:\n",
      "[[18  0]\n",
      " [ 1  4]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "confusion matrix of RandomForest:\n",
      "[[18  0]\n",
      " [ 2  3]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "confusion matrix of AdaBoost:\n",
      "[[18  0]\n",
      " [ 1  4]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "confusion matrix of Perceptron:\n",
      "[[18  0]\n",
      " [ 0  5]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'confusion matrix of logistic:\\n{confusion_matrix(y_valid,y_pred_lg)}\\n'+'-'*100)\n",
    "print(f'confusion matrix of SVM:\\n{confusion_matrix(y_valid,y_pred_svm)}\\n'+'-'*100)\n",
    "print(f'confusion matrix of naive bayes:\\n{confusion_matrix(y_valid,y_pred_nb)}\\n'+'-'*100)\n",
    "print(f'confusion matrix of DecisionTree:\\n{confusion_matrix(y_valid,y_pred_dt)}\\n'+'-'*100)\n",
    "print(f'confusion matrix of RandomForest:\\n{confusion_matrix(y_valid,y_pred_rf)}\\n'+'-'*100)\n",
    "print(f'confusion matrix of AdaBoost:\\n{confusion_matrix(y_valid,y_pred_ada)}\\n'+'-'*100)\n",
    "print(f'confusion matrix of Perceptron:\\n{confusion_matrix(y_valid,y_pred_per)}\\n'+'-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid precision score of logistic:1.0\n",
      "valid precision score of SVM:1.0\n",
      "valid precision score of naive bayes:1.0\n",
      "valid precision score of DecisionTree:1.0\n",
      "valid precision score of RandomForest:1.0\n",
      "valid precision score of AdaBoost:1.0\n",
      "valid precision score of Perceptron:1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(f'valid precision score of logistic:{precision_score(y_valid,y_pred_lg)}')\n",
    "print(f'valid precision score of SVM:{precision_score(y_valid,y_pred_svm, zero_division=1)}') # 輸入的數據有positive，但是預測的結果沒有positive⇒此時可以定義Precision為1，因為可以當作False Positive沒有發生\n",
    "print(f'valid precision score of naive bayes:{precision_score(y_valid,y_pred_nb)}')\n",
    "print(f'valid precision score of DecisionTree:{precision_score(y_valid,y_pred_dt)}')\n",
    "print(f'valid precision score of RandomForest:{precision_score(y_valid,y_pred_rf)}')\n",
    "print(f'valid precision score of AdaBoost:{precision_score(y_valid,y_pred_ada)}')\n",
    "print(f'valid precision score of Perceptron:{precision_score(y_valid,y_pred_per)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid recall score of logistic:0.6\n",
      "valid recall score of SVM:0.0\n",
      "valid recall score of naive bayes:0.2\n",
      "valid recall score of DecisionTree:0.8\n",
      "valid recall score of RandomForest:0.6\n",
      "valid recall score of AdaBoost:0.8\n",
      "valid recall score of Perceptron:1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(f'valid recall score of logistic:{recall_score(y_valid,y_pred_lg)}')\n",
    "print(f'valid recall score of SVM:{recall_score(y_valid,y_pred_svm)}')\n",
    "print(f'valid recall score of naive bayes:{recall_score(y_valid,y_pred_nb)}')\n",
    "print(f'valid recall score of DecisionTree:{recall_score(y_valid,y_pred_dt)}')\n",
    "print(f'valid recall score of RandomForest:{recall_score(y_valid,y_pred_rf)}')\n",
    "print(f'valid recall score of AdaBoost:{recall_score(y_valid,y_pred_ada)}')\n",
    "print(f'valid recall score of Perceptron:{recall_score(y_valid,y_pred_per)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結論\n",
    "1. 7個模型都不太會濫捕無辜 (Precision score)\n",
    "2. SVM最容易放縱壞人(recall score 最低)，其次是naive bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 補充 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score of logistic:0.7222222222222222\n",
      "auc score of SVM:0.7111111111111111\n",
      "auc score of naive bayes:0.4333333333333333\n",
      "auc score of DecisionTree:0.6722222222222222\n",
      "auc score of RandomForest:0.8277777777777778\n",
      "auc score of AdaBoost:0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "lg.fit(x_train,y_train)\n",
    "y_prob = lg.predict_proba(x_valid)\n",
    "print(f'auc score of logistic:{roc_auc_score(y_valid,y_prob[:,1])}')\n",
    "svm.fit(x_train,y_train)\n",
    "y_prob = svm.predict_proba(x_valid)\n",
    "print(f'auc score of SVM:{roc_auc_score(y_valid,y_prob[:,1])}')\n",
    "nb.fit(x_train,y_train)\n",
    "y_prob = nb.predict_proba(x_valid)\n",
    "print(f'auc score of naive bayes:{roc_auc_score(y_valid,y_prob[:,1])}')\n",
    "dt.fit(x_train,y_train)\n",
    "y_prob = dt.predict_proba(x_valid)\n",
    "print(f'auc score of DecisionTree:{roc_auc_score(y_valid,y_prob[:,1])}')\n",
    "rf.fit(x_train,y_train)\n",
    "y_prob = rf.predict_proba(x_valid)\n",
    "print(f'auc score of RandomForest:{roc_auc_score(y_valid,y_prob[:,1])}')\n",
    "ada.fit(x_train,y_train)\n",
    "y_prob = ada.predict_proba(x_valid)\n",
    "print(f'auc score of AdaBoost:{roc_auc_score(y_valid,y_prob[:,1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "train_data = pd.read_csv('./data/Enron_Fraud/Enron_train_data.csv')\n",
    "test_features = pd.read_csv('./data/Enron_Fraud/Enron_test_features.csv')\n",
    "features = test_features.columns.tolist()\n",
    "train_data_y = train_data['poi']\n",
    "train_data = train_data.drop(['poi'],axis=1)\n",
    "pre_process_data  = pd.concat([train_data,test_features])\n",
    "pre_process_data = pre_process_data.drop(['name','email_address'],axis = 1)\n",
    "features = [i for i in features if i not in ['name','email_address']]\n",
    "pre_process_data = pre_process_data.fillna(0)\n",
    "train_data = pre_process_data[:len(train_data_y)]\n",
    "test_data = pre_process_data[len(train_data_y):]\n",
    "mms = MinMaxScaler()\n",
    "mms_ = mms.fit(train_data)\n",
    "train_data = mms_.transform(train_data)\n",
    "test_data = mms_.transform(test_data)\n",
    "train_data = pd.DataFrame(train_data,columns=features)\n",
    "train_data_clean = pd.concat([train_data,train_data_y],axis = 1)\n",
    "test_data_clean = pd.DataFrame(test_data,columns=features)\n",
    "train_data_clean.to_csv('./data/output/Enron_train_data_clean.csv')\n",
    "test_data_clean.to_csv('./data/output/Enron_test_features_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
